{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias basicas\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import IterableDataset\n",
    "#from PIL import Image, ImageDraw\n",
    "#import pandas as pd\n",
    "#import os\n",
    "import cv2\n",
    "#import random\n",
    "#import math\n",
    "import torch.nn as nn\n",
    "#import time\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga de datos X,Y\n",
    "dataset_images = np.load(\"X_data_gray.npy\",allow_pickle=True)\n",
    "dataset_points = np.load(\"Y_data_Pos_EF.npy\",allow_pickle=True)\n",
    "dataset_mask = np.load(\"Y_data_mask.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------UNET----------------------------------##\n",
    "def conv3x3_bn(ci, co):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(ci, co, 3, padding=1),\n",
    "        torch.nn.BatchNorm2d(co),\n",
    "        torch.nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def encoder_conv(ci, co):\n",
    "  return torch.nn.Sequential(\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        conv3x3_bn(ci, co),\n",
    "        conv3x3_bn(co, co),\n",
    "    )\n",
    "\n",
    "class deconv(torch.nn.Module):\n",
    "    def __init__(self, ci, co):\n",
    "        super(deconv, self).__init__()\n",
    "        self.upsample = torch.nn.ConvTranspose2d(ci, co, 2, stride=2)\n",
    "        self.conv1 = conv3x3_bn(ci, co)\n",
    "        self.conv2 = conv3x3_bn(co, co)\n",
    "    \n",
    "    # recibe la salida de la capa anetrior y la salida de la etapa\n",
    "    # correspondiente del encoder\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.upsample(x1)\n",
    "        diffX = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, (diffX, 0, diffY, 0))\n",
    "        # concatenamos los tensores\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes=1, in_ch=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # lista de capas en encoder-decoder con número de filtros\n",
    "        c = [16, 32, 64, 128]\n",
    "\n",
    "        # primera capa conv que recibe la imagen\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "          conv3x3_bn(in_ch, c[0]),\n",
    "          conv3x3_bn(c[0], c[0]),\n",
    "        )\n",
    "        # capas del encoder\n",
    "        self.conv2 = encoder_conv(c[0], c[1])\n",
    "        self.conv3 = encoder_conv(c[1], c[2])\n",
    "        self.conv4 = encoder_conv(c[2], c[3])\n",
    "\n",
    "        # capas del decoder\n",
    "        self.deconv1 = deconv(c[3],c[2])\n",
    "        self.deconv2 = deconv(c[2],c[1])\n",
    "        self.deconv3 = deconv(c[1],c[0])\n",
    "\n",
    "        # útlima capa conv que nos da la máscara\n",
    "        self.out = torch.nn.Conv2d(c[0], n_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x2)\n",
    "        x = self.conv4(x3)\n",
    "        # decoder\n",
    "        x = self.deconv1(x, x3)\n",
    "        x = self.deconv2(x, x2)\n",
    "        x = self.deconv3(x, x1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrica\n",
    "def iou(outputs, labels):\n",
    "    # aplicar sigmoid y convertir a binario\n",
    "    outputs, labels = torch.sigmoid(outputs) > 0.5, labels > 0.5\n",
    "    SMOOTH = 1e-6\n",
    "    # BATCH x num_classes x H x W\n",
    "    \n",
    "    ious = []\n",
    "    \n",
    "    intersection = (outputs & labels).float().sum((1, 2))  \n",
    "    union = (outputs | labels).float().sum((1, 2))         \n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)  \n",
    "    ious.append(iou.mean().item())\n",
    "    return np.mean(ious) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crear mi dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    # This loads the data and converts it, make data rdy\n",
    "    def __init__(self,X, y):\n",
    "        # load data\n",
    "        N,W,H = X.shape\n",
    "        self.img=torch.tensor(X.reshape(N,1,W,H).astype(np.float32))\n",
    "        self.mask=torch.tensor(y.reshape(N,1,W,H).astype(np.float32))\n",
    "    \n",
    "    # This returns the total amount of samples in your Dataset\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    # This returns given an index the i-th sample and label\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx],self.mask[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,W,H = dataset_images.shape\n",
    "N_training = int(0.7*N)\n",
    "dataset = {\n",
    "    'train': Dataset(dataset_images[0:N_training], dataset_mask[0:N_training]),\n",
    "    'test': Dataset(dataset_images[N_training:N], dataset_mask[N_training:N])\n",
    "}\n",
    "\n",
    "len(dataset['train']), len(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=50, shuffle=True, pin_memory=True),\n",
    "    'test': DataLoader(dataset['test'], batch_size=100, pin_memory=True)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion de entrenamiento\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Si sale algun error con el CUDA relacionado con el espacio, comentar la linea de arriba y descomentar la de abajo\n",
    "#device = \"cpu\"\n",
    "def fit(model, dataloader, epochs=100, lr=3e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    #criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'iou': [], 'test_loss': [], 'test_iou': []}\n",
    "    for epoch in range(1, epochs+1):\n",
    "      bar = tqdm(dataloader['train'])\n",
    "      train_loss, train_iou = [], []\n",
    "      model.train()\n",
    "      for imgs, masks in bar:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(imgs)\n",
    "        loss = criterion(y_hat, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ious = iou(y_hat, masks)\n",
    "        train_loss.append(loss.item())\n",
    "        train_iou.append(ious)\n",
    "        bar.set_description(f\"loss {np.mean(train_loss):.5f} iou {np.mean(train_iou):.5f}\")\n",
    "      hist['loss'].append(np.mean(train_loss))\n",
    "      hist['iou'].append(np.mean(train_iou))\n",
    "      bar = tqdm(dataloader['test'])\n",
    "      test_loss, test_iou = [], []\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        for imgs, masks in bar:\n",
    "          imgs, masks = imgs.to(device), masks.to(device)\n",
    "          y_hat = model(imgs)\n",
    "          loss = criterion(y_hat, masks)\n",
    "          ious = iou(y_hat, masks)\n",
    "          test_loss.append(loss.item())\n",
    "          test_iou.append(ious)\n",
    "          bar.set_description(f\"test_loss {np.mean(test_loss):.5f} test_iou {np.mean(test_iou):.5f}\")\n",
    "      hist['test_loss'].append(np.mean(test_loss))\n",
    "      hist['test_iou'].append(np.mean(test_iou))\n",
    "      print(f\"\\nEpoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} iou {np.mean(train_iou):.5f} test_loss {np.mean(test_loss):.5f} test_iou {np.mean(test_iou):.5f}\")\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "hist = fit(model, dataloader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar modelo\n",
    "torch.save(model, 'mi_modelo_name.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
